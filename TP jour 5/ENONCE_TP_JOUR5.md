# TP Jour 5 - Architecture Microservices IA & Gouvernance
## Syst√®me de D√©tection d'Objets Automobiles
**Master 2 - Industrialisation IA dans le Cloud**  
**Dur√©e : 3 heures** 

---

## Contexte du projet

Vous √™tes data scientist dans une entreprise sp√©cialis√©e dans les syst√®mes d'aide √† la conduite (ADAS - Advanced Driver Assistance Systems). Votre mission est de d√©ployer un syst√®me de d√©tection d'objets automobiles en production, en respectant les principes d'architecture microservices et les exigences de gouvernance IA.

Le syst√®me doit :
- D√©tecter et classifier les v√©hicules dans des images (voitures, camions, bus)
- √ätre d√©ploy√© sous forme de microservices ind√©pendants
- Respecter les principes de gouvernance IA et de conformit√© RGPD
- √ätre auditable et tra√ßable

**Dataset** : [Car Object Detection - Kaggle](https://www.kaggle.com/datasets/sshikamaru/car-object-detection)

---

## Objectifs p√©dagogiques

√Ä l'issue de ce TP, vous serez capable de :

1. Concevoir et d√©ployer une architecture microservices pour un syst√®me IA
2. Impl√©menter diff√©rents patterns de communication (REST, gRPC)
3. Mettre en place un syst√®me de logging et monitoring centralis√©
4. Appliquer un cadre de gouvernance IA (transparence, tra√ßabilit√©, conformit√©)
5. G√©n√©rer des rapports d'audit et de conformit√© RGPD

---

## üì¶ Pr√©requis techniques

### Logiciels requis
- Docker Desktop (version 20.10+)
- Docker Compose (version 2.0+)
- Python 3.9+
- kubectl (pour la partie Kubernetes)
- minikube ou kind (cluster Kubernetes local)
- Git
- Un √©diteur de code (VS Code recommand√©)

### Connaissances requises
- Bases de Docker et conteneurisation
- Python et biblioth√®ques ML (scikit-learn, TensorFlow/PyTorch)
- API REST
- Notions de Kubernetes (niveau d√©butant acceptable)

### V√©rification de l'environnement

```bash
# V√©rifier Docker
docker --version
docker-compose --version

# V√©rifier Python
python --version
pip --version

# V√©rifier Kubernetes
kubectl version --client
minikube version  # ou kind version

# V√©rifier Git
git --version
```

---

##  Architecture du syst√®me

Le syst√®me est compos√© de 5 microservices :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      API Gateway (Kong)                      ‚îÇ
‚îÇ            Routage ‚Ä¢ Auth ‚Ä¢ Rate Limiting                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                ‚îÇ                ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Model      ‚îÇ  ‚îÇ  Feature    ‚îÇ  ‚îÇ  Results   ‚îÇ
‚îÇ   Serving    ‚îÇ  ‚îÇ  Service    ‚îÇ  ‚îÇ  Service   ‚îÇ
‚îÇ   (gRPC)     ‚îÇ  ‚îÇ  (REST)     ‚îÇ  ‚îÇ  (REST)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                ‚îÇ                ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ  Logging &      ‚îÇ
                ‚îÇ  Monitoring     ‚îÇ
                ‚îÇ  (ELK Stack)    ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Description des services

1. **API Gateway** : Point d'entr√©e unique, gestion de l'authentification et du rate limiting
2. **Model Serving** : Service d'inf√©rence du mod√®le de d√©tection (communication gRPC)
3. **Feature Service** : Pr√©traitement et extraction de features des images (REST)
4. **Results Service** : Stockage et r√©cup√©ration des r√©sultats de pr√©diction (REST)
5. **Logging & Monitoring** : Centralisation des logs et m√©triques (ELK Stack)

---

## Partie 1 : Pr√©paration des donn√©es et du mod√®le (30 min)

### √âtape 1.1 : R√©cup√©ration et exploration du dataset

1. T√©l√©chargez le dataset depuis Kaggle :
   ```bash
   # Installer kaggle CLI
   pip install kaggle
   
   # Configurer les credentials Kaggle (fichier ~/.kaggle/kaggle.json)
   # T√©l√©charger le dataset
   kaggle datasets download -d sshikamaru/car-object-detection
   unzip car-object-detection.zip -d data/
   ```

2. Explorez la structure du dataset :
   ```bash
   data/
   ‚îú‚îÄ‚îÄ images/           # Images de v√©hicules
   ‚îú‚îÄ‚îÄ annotations/      # Annotations au format YOLO ou COCO
   ‚îî‚îÄ‚îÄ classes.txt       # Liste des classes
   ```

3. **Question de r√©flexion** : 
   - Combien d'images contient le dataset ?
   - Quelles sont les classes d'objets pr√©sentes ?
   - Quelle est la distribution des classes (√©quilibr√©e ou d√©s√©quilibr√©e) ?

### √âtape 1.2 : Entra√Ænement d'un mod√®le de d√©tection

Pour ce TP, nous utiliserons un mod√®le pr√©-entra√Æn√© (transfer learning) pour gagner du temps.

Cr√©ez le fichier `model/train_model.py` :

```python
"""
Script d'entra√Ænement du mod√®le de d√©tection d'objets automobiles
Utilise un mod√®le pr√©-entra√Æn√© (MobileNetV2) avec transfer learning
"""

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
import numpy as np
import json
from datetime import datetime

# TODO : Impl√©menter la fonction de chargement des donn√©es
def load_dataset(data_path, img_size=(224, 224)):
    """
    Charge et pr√©traite le dataset
    
    Args:
        data_path: Chemin vers le dossier de donn√©es
        img_size: Taille des images (hauteur, largeur)
    
    Returns:
        X_train, y_train, X_val, y_val, class_names
    """
    # √Ä COMPL√âTER
    pass

# TODO : Impl√©menter la fonction de cr√©ation du mod√®le
def create_model(num_classes, input_shape=(224, 224, 3)):
    """
    Cr√©e un mod√®le de classification bas√© sur MobileNetV2
    
    Args:
        num_classes: Nombre de classes √† pr√©dire
        input_shape: Forme des images d'entr√©e
    
    Returns:
        model: Mod√®le Keras compil√©
    """
    # √Ä COMPL√âTER
    # Indice : Utiliser MobileNetV2 pr√©-entra√Æn√© sur ImageNet
    # Ajouter une couche de classification personnalis√©e
    pass

# TODO : Impl√©menter la fonction d'entra√Ænement
def train_model(model, X_train, y_train, X_val, y_val, epochs=10):
    """
    Entra√Æne le mod√®le
    
    Args:
        model: Mod√®le Keras
        X_train, y_train: Donn√©es d'entra√Ænement
        X_val, y_val: Donn√©es de validation
        epochs: Nombre d'√©poques
    
    Returns:
        history: Historique d'entra√Ænement
    """
    # √Ä COMPL√âTER
    pass

# TODO : Impl√©menter la sauvegarde du mod√®le avec m√©tadonn√©es
def save_model_with_metadata(model, history, output_path="models/"):
    """
    Sauvegarde le mod√®le avec ses m√©tadonn√©es (pour la gouvernance)
    
    Args:
        model: Mod√®le entra√Æn√©
        history: Historique d'entra√Ænement
        output_path: Chemin de sauvegarde
    """
    # √Ä COMPL√âTER
    # Sauvegarder :
    # - Le mod√®le (.h5 ou SavedModel)
    # - Les m√©triques d'entra√Ænement
    # - Les m√©tadonn√©es (date, version, hyperparam√®tres)
    pass

if __name__ == "__main__":
    print(" D√©marrage de l'entra√Ænement du mod√®le...")
    
    # Configuration
    DATA_PATH = "data/"
    NUM_CLASSES = 3  # voiture, camion, bus
    EPOCHS = 10
    
    # Pipeline d'entra√Ænement
    # √Ä COMPL√âTER
```

**Livrables Partie 1** :
- [ ] Script `train_model.py` compl√©t√© et fonctionnel
- [ ] Mod√®le entra√Æn√© sauvegard√© dans `models/car_detector_v1.h5`
- [ ] Fichier `models/model_metadata.json` contenant les m√©tadonn√©es

**Aide** : Consultez `AIDE_PARTIE1.md` pour des indices sur l'impl√©mentation.

---

## Partie 2 : Conteneurisation des microservices (45 min)

### √âtape 2.1 : Service de Model Serving (gRPC)

Cr√©ez le service d'inf√©rence qui expose le mod√®le via gRPC.

**Fichier : `services/model_serving/server.py`**

```python
"""
Service de Model Serving - Communication gRPC
Expose le mod√®le de d√©tection via une API gRPC haute performance
"""

import grpc
from concurrent import futures
import tensorflow as tf
import numpy as np
import logging
from datetime import datetime
import json

# TODO : Importer les proto g√©n√©r√©s
# import model_serving_pb2
# import model_serving_pb2_grpc

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ModelServingService:
    """Service gRPC pour l'inf√©rence du mod√®le"""
    
    def __init__(self, model_path):
        """
        Initialise le service avec le mod√®le
        
        Args:
            model_path: Chemin vers le mod√®le sauvegard√©
        """
        # TODO : Charger le mod√®le
        # self.model = ...
        # self.class_names = ...
        logger.info(f" Mod√®le charg√© depuis {model_path}")
    
    def Predict(self, request, context):
        """
        M√©thode gRPC pour la pr√©diction
        
        Args:
            request: Requ√™te contenant l'image encod√©e
            context: Contexte gRPC
        
        Returns:
            PredictionResponse avec les r√©sultats
        """
        try:
            # TODO : Impl√©menter la logique de pr√©diction
            # 1. D√©coder l'image depuis request.image_data
            # 2. Pr√©traiter l'image
            # 3. Faire la pr√©diction
            # 4. Logger la pr√©diction (pour l'audit)
            # 5. Retourner le r√©sultat
            
            logger.info(f"üìä Pr√©diction effectu√©e - ID: {request.request_id}")
            pass
            
        except Exception as e:
            logger.error(f" Erreur lors de la pr√©diction: {str(e)}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(str(e))
            return None

def serve():
    """D√©marre le serveur gRPC"""
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    # TODO : Enregistrer le service
    # model_serving_pb2_grpc.add_ModelServingServicer_to_server(
    #     ModelServingService(model_path="models/car_detector_v1.h5"), 
    #     server
    # )
    server.add_insecure_port('[::]:50051')
    server.start()
    logger.info("üöÄ Serveur gRPC d√©marr√© sur le port 50051")
    server.wait_for_termination()

if __name__ == '__main__':
    serve()
```

**Fichier : `services/model_serving/model_serving.proto`**

```protobuf
syntax = "proto3";

package modelserving;

// Service de pr√©diction
service ModelServing {
  rpc Predict (PredictionRequest) returns (PredictionResponse);
  rpc HealthCheck (HealthCheckRequest) returns (HealthCheckResponse);
}

// Requ√™te de pr√©diction
message PredictionRequest {
  string request_id = 1;
  bytes image_data = 2;  // Image encod√©e en base64
  string user_id = 3;    // Pour la tra√ßabilit√©
}

// R√©ponse de pr√©diction
message PredictionResponse {
  string request_id = 1;
  repeated Detection detections = 2;
  string model_version = 3;
  double inference_time_ms = 4;
}

// D√©tection d'un objet
message Detection {
  string class_name = 1;
  double confidence = 2;
  BoundingBox bbox = 3;
}

// Bo√Æte englobante
message BoundingBox {
  double x_min = 1;
  double y_min = 2;
  double x_max = 3;
  double y_max = 4;
}

// Health check
message HealthCheckRequest {}
message HealthCheckResponse {
  string status = 1;
}
```

**Fichier : `services/model_serving/Dockerfile`**

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Installer les d√©pendances syst√®me
RUN apt-get update && apt-get install -y \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Copier les requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copier le code du service
COPY . .

# G√©n√©rer les proto
RUN python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. model_serving.proto

# Exposer le port gRPC
EXPOSE 50051

# Commande de d√©marrage
CMD ["python", "server.py"]
```

**Fichier : `services/model_serving/requirements.txt`**

```
tensorflow==2.15.0
grpcio==1.60.0
grpcio-tools==1.60.0
numpy==1.24.3
pillow==10.2.0
```

### √âtape 2.2 : Service de Features (REST)

Cr√©ez le service de pr√©traitement des images.

**Fichier : `services/feature_service/app.py`**

```python
"""
Feature Service - API REST
Pr√©traite les images et extrait les features avant l'inf√©rence
"""

from flask import Flask, request, jsonify
import numpy as np
from PIL import Image
import io
import base64
import logging
from datetime import datetime

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# TODO : Impl√©menter les fonctions de pr√©traitement

def preprocess_image(image_bytes, target_size=(224, 224)):
    """
    Pr√©traite une image pour l'inf√©rence
    
    Args:
        image_bytes: Image en bytes
        target_size: Taille cible
    
    Returns:
        Image pr√©trait√©e encod√©e en base64
    """
    # √Ä COMPL√âTER
    pass

def extract_features(image_array):
    """
    Extrait des features basiques de l'image (pour le monitoring)
    
    Args:
        image_array: Image sous forme de numpy array
    
    Returns:
        dict: Dictionnaire de features
    """
    # √Ä COMPL√âTER
    # Exemples de features :
    # - Dimensions
    # - Luminosit√© moyenne
    # - Contraste
    # - Format
    pass

@app.route('/health', methods=['GET'])
def health():
    """Endpoint de health check"""
    return jsonify({
        "status": "healthy",
        "service": "feature-service",
        "timestamp": datetime.utcnow().isoformat()
    })

@app.route('/preprocess', methods=['POST'])
def preprocess():
    """
    Endpoint de pr√©traitement d'image
    
    Body:
        {
            "image": "base64_encoded_image",
            "request_id": "unique_id"
        }
    
    Returns:
        {
            "preprocessed_image": "base64_encoded",
            "features": {...},
            "request_id": "unique_id"
        }
    """
    try:
        # TODO : Impl√©menter la logique
        # 1. R√©cup√©rer l'image depuis la requ√™te
        # 2. D√©coder l'image
        # 3. Pr√©traiter l'image
        # 4. Extraire les features
        # 5. Logger l'op√©ration
        # 6. Retourner le r√©sultat
        
        logger.info(f"Image pr√©trait√©e - ID: {data.get('request_id')}")
        pass
        
    except Exception as e:
        logger.error(f" Erreur de pr√©traitement: {str(e)}")
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5001, debug=False)
```

**Fichier : `services/feature_service/Dockerfile`**

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Copier les requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copier le code
COPY . .

# Exposer le port
EXPOSE 5001

# Commande de d√©marrage
CMD ["python", "app.py"]
```

**Fichier : `services/feature_service/requirements.txt`**

```
flask==3.0.0
pillow==10.2.0
numpy==1.24.3
```

### √âtape 2.3 : Service de Results (REST)

Cr√©ez le service de stockage des r√©sultats.

**Fichier : `services/results_service/app.py`**

```python
"""
Results Service - API REST
Stocke et r√©cup√®re les r√©sultats de pr√©diction
"""

from flask import Flask, request, jsonify
from datetime import datetime
import json
import sqlite3
import logging

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# TODO : Initialiser la base de donn√©es SQLite
def init_db():
    """Initialise la base de donn√©es"""
    # √Ä COMPL√âTER
    # Cr√©er une table 'predictions' avec les colonnes :
    # - id (PRIMARY KEY)
    # - request_id (UNIQUE)
    # - user_id (pour la tra√ßabilit√© RGPD)
    # - predictions (JSON)
    # - model_version
    # - inference_time_ms
    # - timestamp
    pass

@app.route('/health', methods=['GET'])
def health():
    """Endpoint de health check"""
    return jsonify({
        "status": "healthy",
        "service": "results-service",
        "timestamp": datetime.utcnow().isoformat()
    })

@app.route('/predictions', methods=['POST'])
def store_prediction():
    """
    Stocke un r√©sultat de pr√©diction
    
    Body:
        {
            "request_id": "unique_id",
            "user_id": "anonymized_user_id",
            "predictions": [...],
            "model_version": "v1",
            "inference_time_ms": 45.2
        }
    """
    try:
        # TODO : Impl√©menter la logique de stockage
        # 1. R√©cup√©rer les donn√©es
        # 2. Valider les donn√©es
        # 3. Stocker dans la base de donn√©es
        # 4. Logger l'op√©ration
        
        logger.info(f" Pr√©diction stock√©e - ID: {data.get('request_id')}")
        pass
        
    except Exception as e:
        logger.error(f"Erreur de stockage: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/predictions/<request_id>', methods=['GET'])
def get_prediction(request_id):
    """R√©cup√®re un r√©sultat de pr√©diction par son ID"""
    try:
        # TODO : Impl√©menter la r√©cup√©ration
        pass
        
    except Exception as e:
        logger.error(f"Erreur de r√©cup√©ration: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/predictions/user/<user_id>', methods=['GET'])
def get_user_predictions(user_id):
    """
    R√©cup√®re toutes les pr√©dictions d'un utilisateur
    (Important pour le droit d'acc√®s RGPD)
    """
    try:
        # TODO : Impl√©menter la r√©cup√©ration
        pass
        
    except Exception as e:
        logger.error(f"Erreur de r√©cup√©ration: {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route('/predictions/user/<user_id>', methods=['DELETE'])
def delete_user_predictions(user_id):
    """
    Supprime toutes les pr√©dictions d'un utilisateur
    (Important pour le droit √† l'oubli RGPD)
    """
    try:
        # TODO : Impl√©menter la suppression
        # Logger l'op√©ration pour l'audit
        
        logger.info(f"üóëÔ∏è Donn√©es supprim√©es pour l'utilisateur: {user_id}")
        pass
        
    except Exception as e:
        logger.error(f"Erreur de suppression: {str(e)}")
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    init_db()
    app.run(host='0.0.0.0', port=5002, debug=False)
```

**Fichier : `services/results_service/Dockerfile`**

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Copier les requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copier le code
COPY . .

# Cr√©er le dossier pour la base de donn√©es
RUN mkdir -p /app/data

# Exposer le port
EXPOSE 5002

# Commande de d√©marrage
CMD ["python", "app.py"]
```

**Fichier : `services/results_service/requirements.txt`**

```
flask==3.0.0
```

### √âtape 2.4 : Docker Compose

Cr√©ez le fichier `docker-compose.yml` pour orchestrer tous les services.

```yaml
version: '3.8'

services:
  # Service de Model Serving (gRPC)
  model-serving:
    build: ./services/model_serving
    container_name: model-serving
    ports:
      - "50051:50051"
    volumes:
      - ./models:/app/models:ro
    environment:
      - MODEL_PATH=/app/models/car_detector_v1.h5
      - LOG_LEVEL=INFO
    networks:
      - ia-network
    restart: unless-stopped

  # Service de Features (REST)
  feature-service:
    build: ./services/feature_service
    container_name: feature-service
    ports:
      - "5001:5001"
    environment:
      - LOG_LEVEL=INFO
    networks:
      - ia-network
    restart: unless-stopped

  # Service de Results (REST)
  results-service:
    build: ./services/results_service
    container_name: results-service
    ports:
      - "5002:5002"
    volumes:
      - ./data/results:/app/data
    environment:
      - LOG_LEVEL=INFO
      - DB_PATH=/app/data/predictions.db
    networks:
      - ia-network
    restart: unless-stopped

  # TODO : Ajouter les services de logging (ELK Stack)
  # elasticsearch:
  #   ...
  
  # logstash:
  #   ...
  
  # kibana:
  #   ...

networks:
  ia-network:
    driver: bridge

volumes:
  elasticsearch-data:
```

**Livrables Partie 2** :
- [ ] Services conteneuris√©s et fonctionnels
- [ ] `docker-compose.yml` compl√©t√©
- [ ] Tous les services d√©marrent sans erreur
- [ ] Tests de communication entre services

**Commandes de test** :
```bash
# Construire et d√©marrer les services
docker-compose up --build -d

# V√©rifier les logs
docker-compose logs -f

# Tester le health check
curl http://localhost:5001/health
curl http://localhost:5002/health
```

---

## Partie 3 : Logging et Monitoring centralis√©s (30 min)

### √âtape 3.1 : Configuration de l'ELK Stack

Ajoutez les services Elasticsearch, Logstash et Kibana √† votre `docker-compose.yml`.

```yaml
  # Elasticsearch - Stockage des logs
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - ia-network
    restart: unless-stopped

  # Logstash - Pipeline de traitement des logs
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash
    volumes:
      - ./config/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro
    ports:
      - "5000:5000"
      - "9600:9600"
    environment:
      - "LS_JAVA_OPTS=-Xmx256m -Xms256m"
    depends_on:
      - elasticsearch
    networks:
      - ia-network
    restart: unless-stopped

  # Kibana - Visualisation des logs
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - ia-network
    restart: unless-stopped
```

### √âtape 3.2 : Configuration de Logstash

Cr√©ez le fichier `config/logstash/logstash.conf` :

```ruby
input {
  # R√©ception des logs depuis les services
  tcp {
    port => 5000
    codec => json
  }
}

filter {
  # TODO : Ajouter des filtres pour enrichir les logs
  # Exemples :
  # - Ajouter un timestamp
  # - Extraire des champs sp√©cifiques
  # - Classifier les logs par niveau (INFO, WARNING, ERROR)
  
  # Anonymisation des donn√©es sensibles (RGPD)
  if [user_id] {
    mutate {
      # Hasher le user_id pour l'anonymisation
      add_field => { "user_id_hash" => "%{user_id}" }
      remove_field => [ "user_id" ]
    }
  }
}

output {
  # Envoi vers Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "ia-logs-%{+YYYY.MM.dd}"
  }
  
  # Debug (optionnel)
  stdout {
    codec => rubydebug
  }
}
```

### √âtape 3.3 : Int√©gration du logging dans les services

Modifiez vos services pour envoyer les logs vers Logstash.

**Exemple pour le Feature Service** :

```python
import logging
import logstash
import socket

# Configuration du logger avec Logstash
logger = logging.getLogger('feature-service')
logger.setLevel(logging.INFO)

# Handler vers Logstash
logstash_handler = logstash.TCPLogstashHandler(
    host='logstash',
    port=5000,
    version=1
)
logger.addHandler(logstash_handler)

# Utilisation
logger.info('Image pr√©trait√©e', extra={
    'request_id': request_id,
    'service': 'feature-service',
    'operation': 'preprocess',
    'duration_ms': duration
})
```

**Livrables Partie 3** :
- [ ] ELK Stack d√©ploy√© et fonctionnel
- [ ] Logs centralis√©s depuis tous les services
- [ ] Dashboard Kibana configur√©
- [ ] Visualisations des m√©triques cl√©s

**Questions de r√©flexion** :
- Pourquoi est-il important de centraliser les logs ?
- Comment l'anonymisation des donn√©es contribue-t-elle √† la conformit√© RGPD ?
- Quelles m√©triques sont essentielles pour le monitoring d'un syst√®me IA ?

---

## Partie 4 : Gouvernance IA et conformit√© RGPD (45 min)

### √âtape 4.1 : Cr√©ation d'une checklist de gouvernance

Cr√©ez le fichier `governance/CHECKLIST_GOUVERNANCE.md` :

```markdown
# Checklist de Gouvernance IA
## Syst√®me de D√©tection d'Objets Automobiles

### 1. Transparence des donn√©es

- [ ] **Origine des donn√©es** : Dataset Kaggle document√©
- [ ] **Qualit√© des donn√©es** : V√©rification de la distribution des classes
- [ ] **Biais potentiels** : Analyse des biais (g√©ographiques, temporels, etc.)
- [ ] **Documentation** : M√©tadonn√©es compl√®tes du dataset

**Notes** :
- Dataset : Car Object Detection - Kaggle
- Nombre d'images : [√Ä COMPL√âTER]
- Classes : [√Ä COMPL√âTER]
- Biais identifi√©s : [√Ä COMPL√âTER]

### 2. Transparence du mod√®le

- [ ] **Architecture** : Documentation de l'architecture (MobileNetV2)
- [ ] **Hyperparam√®tres** : Liste compl√®te des hyperparam√®tres
- [ ] **M√©triques de performance** : Accuracy, Precision, Recall, F1-Score
- [ ] **Limitations** : Documentation des limitations connues

**M√©triques** :
- Accuracy : [√Ä COMPL√âTER]
- Precision : [√Ä COMPL√âTER]
- Recall : [√Ä COMPL√âTER]
- F1-Score : [√Ä COMPL√âTER]

### 3. √âquit√© et non-discrimination

- [ ] **Analyse des biais** : Test sur diff√©rents sous-groupes
- [ ] **Fairness metrics** : Calcul des m√©triques d'√©quit√©
- [ ] **Mitigation** : Strat√©gies de r√©duction des biais
- [ ] **Monitoring continu** : Surveillance des biais en production

**Actions** :
- [√Ä COMPL√âTER]

### 4. Conformit√© RGPD

- [ ] **Base l√©gale** : Int√©r√™t l√©gitime / Consentement
- [ ] **Minimisation des donn√©es** : Collecte uniquement des donn√©es n√©cessaires
- [ ] **Droit d'acc√®s** : API pour r√©cup√©rer les donn√©es utilisateur
- [ ] **Droit √† l'oubli** : API pour supprimer les donn√©es utilisateur
- [ ] **Anonymisation** : Pseudonymisation des identifiants
- [ ] **Chiffrement** : Donn√©es en transit (TLS) et au repos
- [ ] **Registre des traitements** : Documentation RGPD compl√®te

**Endpoints RGPD** :
- GET /predictions/user/<user_id> : Droit d'acc√®s
- DELETE /predictions/user/<user_id> : Droit √† l'oubli

### 5. S√©curit√©

- [ ] **Authentification** : M√©canisme d'authentification en place
- [ ] **Autorisation** : Contr√¥le d'acc√®s bas√© sur les r√¥les
- [ ] **Chiffrement** : TLS pour toutes les communications
- [ ] **Audit** : Journalisation de tous les acc√®s
- [ ] **Gestion des incidents** : Proc√©dure de r√©ponse aux incidents

**Mesures** :
- [√Ä COMPL√âTER]

### 6. Auditabilit√© et tra√ßabilit√©

- [ ] **Versioning** : Gestion des versions du mod√®le
- [ ] **Logging** : Journalisation de toutes les pr√©dictions
- [ ] **M√©triques** : Collecte des m√©triques de performance
- [ ] **Alertes** : Syst√®me d'alertes pour les anomalies
- [ ] **Rapports** : G√©n√©ration automatique de rapports d'audit

**Outils** :
- Versioning : MLflow / DVC
- Logging : ELK Stack
- Monitoring : Kibana Dashboards

### 7. Responsabilit√©

- [ ] **Propri√©taire du mod√®le** : [√Ä COMPL√âTER]
- [ ] **Responsable des donn√©es** : [√Ä COMPL√âTER]
- [ ] **DPO (Data Protection Officer)** : [√Ä COMPL√âTER]
- [ ] **Cha√Æne de responsabilit√©** : Document√©e et claire

### 8. Explicabilit√©

- [ ] **Documentation utilisateur** : Guide d'utilisation du syst√®me
- [ ] **Interpr√©tabilit√©** : M√©thodes d'explication des pr√©dictions (LIME, SHAP)
- [ ] **Feedback** : M√©canisme de retour utilisateur
- [ ] **Recours** : Proc√©dure de contestation des d√©cisions

**M√©thodes** :
- [√Ä COMPL√âTER]

---

**Date de cr√©ation** : [DATE]  
**Derni√®re mise √† jour** : [DATE]  
**Version** : 1.0  
**Valid√© par** : [NOM]
```

### √âtape 4.2 : Impl√©mentation du versioning du mod√®le

Cr√©ez le fichier `governance/model_registry.py` :

```python
"""
Registre des mod√®les - Gestion des versions et m√©tadonn√©es
"""

import json
import hashlib
from datetime import datetime
from pathlib import Path

class ModelRegistry:
    """Registre centralis√© des mod√®les ML"""
    
    def __init__(self, registry_path="governance/model_registry.json"):
        self.registry_path = Path(registry_path)
        self.registry = self._load_registry()
    
    def _load_registry(self):
        """Charge le registre depuis le fichier JSON"""
        if self.registry_path.exists():
            with open(self.registry_path, 'r') as f:
                return json.load(f)
        return {"models": []}
    
    def _save_registry(self):
        """Sauvegarde le registre dans le fichier JSON"""
        self.registry_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.registry_path, 'w') as f:
            json.dump(self.registry, f, indent=2)
    
    def register_model(self, model_path, metadata):
        """
        Enregistre un nouveau mod√®le avec ses m√©tadonn√©es
        
        Args:
            model_path: Chemin vers le fichier du mod√®le
            metadata: Dict contenant les m√©tadonn√©es
                - name: Nom du mod√®le
                - version: Version
                - description: Description
                - metrics: M√©triques de performance
                - hyperparameters: Hyperparam√®tres
                - training_data: Info sur les donn√©es d'entra√Ænement
                - author: Auteur
        
        Returns:
            model_id: Identifiant unique du mod√®le
        """
        # TODO : Impl√©menter l'enregistrement
        # 1. Calculer le hash du mod√®le (pour l'int√©grit√©)
        # 2. G√©n√©rer un ID unique
        # 3. Ajouter les m√©tadonn√©es au registre
        # 4. Sauvegarder le registre
        pass
    
    def get_model(self, model_id):
        """R√©cup√®re les m√©tadonn√©es d'un mod√®le"""
        # TODO : Impl√©menter
        pass
    
    def list_models(self, name=None, version=None):
        """Liste les mod√®les enregistr√©s"""
        # TODO : Impl√©menter
        pass
    
    def get_latest_version(self, name):
        """R√©cup√®re la derni√®re version d'un mod√®le"""
        # TODO : Impl√©menter
        pass
    
    def deprecate_model(self, model_id, reason):
        """Marque un mod√®le comme d√©pr√©ci√©"""
        # TODO : Impl√©menter
        pass

# Exemple d'utilisation
if __name__ == "__main__":
    registry = ModelRegistry()
    
    # Enregistrer un mod√®le
    metadata = {
        "name": "car_detector",
        "version": "1.0.0",
        "description": "Mod√®le de d√©tection d'objets automobiles bas√© sur MobileNetV2",
        "metrics": {
            "accuracy": 0.92,
            "precision": 0.89,
            "recall": 0.91,
            "f1_score": 0.90
        },
        "hyperparameters": {
            "learning_rate": 0.001,
            "batch_size": 32,
            "epochs": 10,
            "optimizer": "adam"
        },
        "training_data": {
            "dataset": "Car Object Detection - Kaggle",
            "num_samples": 5000,
            "num_classes": 3,
            "split": "80/20 train/val"
        },
        "author": "√âquipe Data Science"
    }
    
    model_id = registry.register_model("models/car_detector_v1.h5", metadata)
    print(f" Mod√®le enregistr√© avec l'ID: {model_id}")
```

### √âtape 4.3 : G√©n√©ration de rapports d'audit

Cr√©ez le fichier `governance/audit_report.py` :

```python
"""
G√©n√©rateur de rapports d'audit et de conformit√©
"""

import sqlite3
import json
from datetime import datetime, timedelta
from pathlib import Path

class AuditReportGenerator:
    """G√©n√®re des rapports d'audit pour la conformit√©"""
    
    def __init__(self, db_path="data/results/predictions.db"):
        self.db_path = db_path
    
    def generate_usage_report(self, period_days=30):
        """
        G√©n√®re un rapport d'utilisation du syst√®me
        
        Args:
            period_days: P√©riode en jours
        
        Returns:
            dict: Rapport d'utilisation
        """
        # TODO : Impl√©menter
        # M√©triques √† inclure :
        # - Nombre total de pr√©dictions
        # - Nombre d'utilisateurs uniques
        # - Temps d'inf√©rence moyen
        # - Distribution des classes pr√©dites
        # - Taux d'erreur
        pass
    
    def generate_compliance_report(self, model_id):
        """
        G√©n√®re un rapport de conformit√© RGPD
        
        Args:
            model_id: ID du mod√®le √† auditer
        
        Returns:
            dict: Rapport de conformit√©
        """
        report = {
            "report_date": datetime.utcnow().isoformat(),
            "model_id": model_id,
            "compliance_checks": {}
        }
        
        # TODO : Impl√©menter les v√©rifications
        # 1. V√©rifier la base l√©gale du traitement
        report["compliance_checks"]["legal_basis"] = {
            "status": "compliant",
            "details": "Int√©r√™t l√©gitime - Syst√®me d'aide √† la conduite"
        }
        
        # 2. V√©rifier la minimisation des donn√©es
        # √Ä COMPL√âTER
        
        # 3. V√©rifier l'anonymisation
        # √Ä COMPL√âTER
        
        # 4. V√©rifier les droits des personnes
        # √Ä COMPL√âTER
        
        # 5. V√©rifier la s√©curit√©
        # √Ä COMPL√âTER
        
        return report
    
    def generate_performance_report(self, period_days=30):
        """
        G√©n√®re un rapport de performance du mod√®le
        
        Args:
            period_days: P√©riode en jours
        
        Returns:
            dict: Rapport de performance
        """
        # TODO : Impl√©menter
        # M√©triques √† inclure :
        # - Temps d'inf√©rence (min, max, moyenne, p95, p99)
        # - Distribution des scores de confiance
        # - D√©tection de drift (si impl√©ment√©)
        # - Disponibilit√© du service
        pass
    
    def export_report(self, report, output_path):
        """
        Exporte un rapport au format JSON et Markdown
        
        Args:
            report: Rapport √† exporter
            output_path: Chemin de sortie (sans extension)
        """
        # Export JSON
        json_path = Path(f"{output_path}.json")
        with open(json_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        # Export Markdown
        md_path = Path(f"{output_path}.md")
        with open(md_path, 'w') as f:
            f.write(self._report_to_markdown(report))
        
        print(f"‚úÖ Rapport export√©: {json_path} et {md_path}")
    
    def _report_to_markdown(self, report):
        """Convertit un rapport en format Markdown"""
        # TODO : Impl√©menter la conversion
        pass

# Exemple d'utilisation
if __name__ == "__main__":
    generator = AuditReportGenerator()
    
    # G√©n√©rer un rapport de conformit√©
    compliance_report = generator.generate_compliance_report("car_detector_v1")
    generator.export_report(
        compliance_report,
        "governance/reports/compliance_report_" + datetime.now().strftime("%Y%m%d")
    )
    
    # G√©n√©rer un rapport d'utilisation
    usage_report = generator.generate_usage_report(period_days=30)
    generator.export_report(
        usage_report,
        "governance/reports/usage_report_" + datetime.now().strftime("%Y%m%d")
    )
```

**Livrables Partie 4** :
- [ ] Checklist de gouvernance compl√©t√©e
- [ ] Registre des mod√®les impl√©ment√©
- [ ] Rapports d'audit g√©n√©r√©s
- [ ] Documentation de conformit√© RGPD


## Partie 5 : D√©ploiement sur Kubernetes (30 min - BONUS)

### √âtape 5.1 : Cr√©ation des manifestes Kubernetes

Cr√©ez les fichiers de d√©ploiement Kubernetes pour chaque service.

**Fichier : `k8s/model-serving-deployment.yaml`**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-serving
  labels:
    app: model-serving
spec:
  replicas: 2
  selector:
    matchLabels:
      app: model-serving
  template:
    metadata:
      labels:
        app: model-serving
    spec:
      containers:
      - name: model-serving
        image: model-serving:v1
        ports:
        - containerPort: 50051
          name: grpc
        env:
        - name: MODEL_PATH
          value: "/app/models/car_detector_v1.h5"
        - name: LOG_LEVEL
          value: "INFO"
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        volumeMounts:
        - name: models
          mountPath: /app/models
          readOnly: true
        livenessProbe:
          exec:
            command:
            - python
            - -c
            - "import grpc; print('OK')"
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - python
            - -c
            - "import grpc; print('OK')"
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: models-pvc

apiVersion: v1
kind: Service
metadata:
  name: model-serving
spec:
  selector:
    app: model-serving
  ports:
  - port: 50051
    targetPort: 50051
    name: grpc
  type: ClusterIP
```

**Fichier : `k8s/feature-service-deployment.yaml`**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: feature-service
  labels:
    app: feature-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: feature-service
  template:
    metadata:
      labels:
        app: feature-service
    spec:
      containers:
      - name: feature-service
        image: feature-service:v1
        ports:
        - containerPort: 5001
          name: http
        env:
        - name: LOG_LEVEL
          value: "INFO"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 5001
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 5001
          initialDelaySeconds: 5
          periodSeconds: 5

apiVersion: v1
kind: Service
metadata:
  name: feature-service
spec:
  selector:
    app: feature-service
  ports:
  - port: 5001
    targetPort: 5001
    name: http
  type: ClusterIP
```

**Fichier : `k8s/results-service-deployment.yaml`**

```yaml
# TODO : √Ä compl√©ter par les √©tudiants
# Similaire aux autres d√©ploiements
```

### √âtape 5.2 : Configuration de l'Ingress

**Fichier : `k8s/ingress.yaml`**

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ia-system-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/rate-limit: "100"
spec:
  rules:
  - host: ia-system.local
    http:
      paths:
      - path: /api/features
        pathType: Prefix
        backend:
          service:
            name: feature-service
            port:
              number: 5001
      - path: /api/results
        pathType: Prefix
        backend:
          service:
            name: results-service
            port:
              number: 5002
```

### √âtape 5.3 : D√©ploiement

```bash
# D√©marrer minikube
minikube start --cpus=4 --memory=8192

# Construire les images dans minikube
eval $(minikube docker-env)
docker build -t model-serving:v1 ./services/model_serving
docker build -t feature-service:v1 ./services/feature_service
docker build -t results-service:v1 ./services/results_service

# Cr√©er le namespace
kubectl create namespace ia-system

# D√©ployer les services
kubectl apply -f k8s/ -n ia-system

# V√©rifier le d√©ploiement
kubectl get pods -n ia-system
kubectl get services -n ia-system

# Acc√©der aux services
minikube service feature-service -n ia-system
```

**Livrables Partie 5** :
- [ ] Manifestes Kubernetes cr√©√©s
- [ ] Services d√©ploy√©s sur minikube
- [ ] Ingress configur√©
- [ ] Tests de scalabilit√© effectu√©s

## Tests et validation

### Tests fonctionnels

Cr√©ez le fichier `tests/test_system.py` :

```python
"""
Tests d'int√©gration du syst√®me complet
"""

import requests
import grpc
import base64
from pathlib import Path

# TODO : Impl√©menter les tests

def test_feature_service_health():
    """Test du health check du feature service"""
    response = requests.get("http://localhost:5001/health")
    assert response.status_code == 200
    assert response.json()["status"] == "healthy"

def test_results_service_health():
    """Test du health check du results service"""
    # √Ä COMPL√âTER
    pass

def test_end_to_end_prediction():
    """Test end-to-end d'une pr√©diction"""
    # 1. Charger une image de test
    # 2. Appeler le feature service
    # 3. Appeler le model serving
    # 4. V√©rifier le r√©sultat
    # 5. V√©rifier le stockage dans results service
    # √Ä COMPL√âTER
    pass

def test_rgpd_user_data_access():
    """Test du droit d'acc√®s RGPD"""
    # √Ä COMPL√âTER
    pass

def test_rgpd_user_data_deletion():
    """Test du droit √† l'oubli RGPD"""
    # √Ä COMPL√âTER
    pass

if __name__ == "__main__":
    print(" Ex√©cution des tests...")
    test_feature_service_health()
    test_results_service_health()
    test_end_to_end_prediction()
    test_rgpd_user_data_access()
    test_rgpd_user_data_deletion()
    print("‚úÖ Tous les tests sont pass√©s!")
```

### Script de test complet

```bash
#!/bin/bash
# tests/run_tests.sh

echo "D√©marrage des tests du syst√®me IA..."

# Test 1 : Health checks
echo "Test 1: Health checks..."
curl -s http://localhost:5001/health | jq
curl -s http://localhost:5002/health | jq

# Test 2: Pr√©traitement d'image
echo "Test 2: Pr√©traitement d'image..."
# √Ä COMPL√âTER

# Test 3: Pr√©diction compl√®te
echo "Test 3: Pr√©diction compl√®te..."
# √Ä COMPL√âTER

# Test 4: V√©rification des logs dans Kibana
echo "Test 4: V√©rification des logs..."
# √Ä COMPL√âTER

# Test 5: Tests RGPD
echo "Test 5: Tests RGPD..."
# √Ä COMPL√âTER

echo "Tests termin√©s!"
```

## Livrables finaux

### Livrables obligatoires

1. **Code fonctionnel** :
   - [ ] Tous les services impl√©ment√©s et fonctionnels
   - [ ] Docker Compose op√©rationnel
   - [ ] Tests passants

2. **Documentation de gouvernance** :
   - [ ] Checklist de gouvernance compl√©t√©e
   - [ ] Registre des mod√®les avec m√©tadonn√©es
   - [ ] Documentation RGPD (base l√©gale, mesures techniques)

3. **Architecture** :
   - [ ] Diagramme d'architecture mis √† jour
   - [ ] Documentation des choix techniques
   - [ ] README.md complet

### Livrables bonus

4. **Rapport d'audit** (BONUS) :
   - [ ] Rapport de conformit√© RGPD g√©n√©r√©
   - [ ] Rapport d'utilisation du syst√®me
   - [ ] Rapport de performance du mod√®le
   - [ ] Recommandations d'am√©lioration

5. **D√©ploiement Kubernetes** (BONUS) :
   - [ ] Manifestes Kubernetes
   - [ ] D√©ploiement sur minikube
   - [ ] Tests de scalabilit√©


## Crit√®res d'√©valuation

| Crit√®re | Points | Description |
|---------|--------|-------------|
| **Architecture microservices** | 25 | Services ind√©pendants, communication REST/gRPC, d√©couplage |
| **Impl√©mentation technique** | 25 | Code propre, fonctionnel, bonnes pratiques |
| **Logging et monitoring** | 15 | ELK Stack configur√©, logs centralis√©s, dashboards |
| **Gouvernance IA** | 20 | Checklist compl√®te, registre des mod√®les, tra√ßabilit√© |
| **Conformit√© RGPD** | 10 | Droits des personnes, anonymisation, documentation |
| **Documentation** | 5 | README, commentaires, architecture |
| **Bonus** | 10 | Rapport d'audit, Kubernetes, fonctionnalit√©s avanc√©es |
| **TOTAL** | 110 | (100 + 10 bonus) |


## Ressources et aide

### Documentation officielle

- **Docker** : https://docs.docker.com/
- **Kubernetes** : https://kubernetes.io/docs/
- **gRPC** : https://grpc.io/docs/
- **Flask** : https://flask.palletsprojects.com/
- **TensorFlow** : https://www.tensorflow.org/
- **ELK Stack** : https://www.elastic.co/guide/

### Fichiers d'aide fournis

- `AIDE_PARTIE1.md` : Indices pour l'entra√Ænement du mod√®le
- `AIDE_PARTIE2.md` : Exemples de code pour les microservices
- `AIDE_PARTIE3.md` : Configuration ELK Stack
- `AIDE_PARTIE4.md` : Exemples de gouvernance IA
- `FAQ.md` : Questions fr√©quentes

### Commandes utiles

```bash
# Docker
docker-compose up --build -d
docker-compose logs -f [service]
docker-compose down

# Kubernetes
kubectl get pods -n ia-system
kubectl logs -f [pod-name] -n ia-system
kubectl describe pod [pod-name] -n ia-system

# Tests
python tests/test_system.py
bash tests/run_tests.sh

# G√©n√©ration de rapports
python governance/audit_report.py
```


## Planning sugg√©r√© (3h)

| Temps | Activit√© |
|-------|----------|
| 0h00 - 0h30 | Partie 1 : Pr√©paration des donn√©es et mod√®le |
| 0h30 - 1h15 | Partie 2 : Conteneurisation des microservices |
| 1h15 - 1h45 | Partie 3 : Logging et monitoring (ELK Stack) |
| 1h45 - 2h30 | Partie 4 : Gouvernance IA et conformit√© RGPD |
| 2h30 - 3h00 | Tests, validation et documentation |



## Questions de r√©flexion finale

1. **Architecture** :
   - Quels sont les avantages et inconv√©nients de l'architecture microservices pour un syst√®me IA ?
   - Pourquoi avons-nous choisi gRPC pour le model serving et REST pour les autres services ?

2. **Gouvernance** :
   - Comment la tra√ßabilit√© des pr√©dictions contribue-t-elle √† la gouvernance IA ?
   - Quelles sont les principales exigences RGPD pour un syst√®me d'IA en production ?

3. **Production** :
   - Quelles m√©triques sont essentielles pour monitorer un syst√®me IA en production ?
   - Comment d√©tecter et g√©rer le drift d'un mod√®le en production ?

4. **√âthique** :
   - Comment garantir l'√©quit√© d'un syst√®me de d√©tection d'objets ?
   - Quels biais potentiels peuvent affecter ce type de syst√®me ?


